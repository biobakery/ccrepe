%% \VignetteIndexEntry{CCREPE}

\documentclass{article}

<<hack, echo=FALSE>>=
tex <- "asis"
@
<<style, echo=FALSE, results=tex>>=
BiocStyle::latex()
@
<<echo=FALSE>>=
library(ccrepe)
options(width=78)
@

\title{CCREPE: Compositionality Corrected by Permutation and Renormalization}
\author{Emma Schwager, George Weingart, Craig Bielski, Curtis Huttenhower}

\begin{document}

\maketitle

\tableofcontents

\section{Introduction}

\Biocpkg{ccrepe} is a package for analysis of sparse compositional data.  Specifically, it determines the significance of association between features in a composition, using any similarity measure (e.g. Pearson correlation, Spearman correlation, etc.)  The CCREPE methodology stands for Compositionality Corrected by Renormalization and Permutation, as detailed below.  The package also provides a novel similarity measure, the N-dimensional checkerboard score (NC-score), particularly appropriate to compositions derived from microbial community sequencing data.  This results in p-values and false discovery rate q-values corrected for the effects of compositionality.  The package contains two functions \Rfunction{ccrepe} and \Rfunction{nc.score} and is maintained by the Huttenhower lab (\email{ccrepe-users@googlegroups.com}).

%---------------------------------------------------------
\section{ccrepe} 
%---------------------------------------------------------

\Rfunction{ccrepe} is the main package function.  It calculates compositionality-corrected p-values and q-values for a user-selected similarity measure, operating on either one or two input matrices.  If given one matrix, all features (columns) in the matrix are compared to each other using the selected similarity measure.  If given two matrices, each feature in the first are compared against all features in the second.

\subsection{General functionality}

Compositional data induces spurious correlations between features due to the nonindependence of values that must sum to a fixed total.  CCREPE abrogates this when determining the significance of a similarity measure for each feature pair using two main steps, permutation/renormalization and bootstrapping.  First, given two features to compare, CCREPE generates a null distribution of the similarity expected just due to compositionality by iteratively permuting one feature, renormalizing all samples in the composition to their previous sum, and computing the resulting similarity measures.  Second, CCREPE bootstraps over sample subsets in order to assess confidence in the "true" similarity measure.  Finally, the two resulting distributions are compared using a pooled-variance Z-test to give a compositionality-corrected p-value.  False discovery rate q-values are additionally calculated using the Benjamin-Hochberg-Yekutieli procedure.  For greater detail, see References.

\subsection{Arguments}

\begin{description}
\setlength{\itemsep}{1em}

\item[\Rcode{x}]
First \Rclass{dataframe} or \Rclass{matrix} containing relative abundances.  Columns are features, rows are samples.  Rows should therefore sum to a constant.  Row names are used for identification if present.

\item[\Rcode{y}]
Second \Rclass{dataframe} or \Rclass{matrix} (optional) containing relative abundances.  Columns are features, rows are samples.  Rows should therefore sum to a constant.  If both \Rcode{x} and \Rcode{y} are specified, they will be merged by row names.  If no row names are specified for either or both datasets,   the default is to merge by row number.

\item[\Rcode{sim.score}]
Similarity measure, such as \Rfunction{cor} or \Rfunction{nc.score}.  This can be either an existing R function or user-defined.  If the latter, certain properties should be satisfied as detailed below (also see examples).  The default similarity measure is Spearman correlation.

A user-defined similarity measure should mimic the interface of \Rfunction{cor}:
\begin{enumerate}
\item Take either two \Rclass{vector} inputs one \Rclass{matrix} or \Rclass{dataframe} input.

\item In the case of two inputs, return a single number.

\item In the case of one input, return a matrix in which the (\Rcode{i},\Rcode{j})th entry is the similarity score for column \Rcode{i} and column \Rcode{j} in the original matrix.

\item The resulting matrix (in the case of one input) must be symmetric.

\item The inputs must be named \Rcode{x} and \Rcode{y}.
\end{enumerate}

\item[\Rcode{sim.score.args}]
An optional list of arguments for the measurement function.  When given, they are passed to the \Rcode{sim.score} function directly.  For example, in the case of cor, the following would be acceptable:

<<eval=FALSE>>=
sim.score.args = list(method="spearman", use="complete.obs")
@

Note that this example corresponds to the default behavior.

\item[\Rcode{min.subj}]
Minimum number (count) of samples that must be nonzero in order to apply the similarity measure.  This is to ensure that there are sufficient samples to perform a bootstrap (default: 20).

\item[\Rcode{iterations}]
The number of iterations for both bootstrap and permutation calculations (default: 1000).

\item[\Rcode{subset.cols.x}]
Subset of columns from \Rcode{x} to work on.  The default (\Rcode{NULL}) uses all columns.  Note that all features are used for normalization, but calculations are performed only with the requested subset.

\item[\Rcode{subset.cols.y}]
Subset of columns from \Rcode{y} to work on.  The default (\Rcode{NULL}) uses all columns.  Note that all features are used for normalization, but calculations are performed only with the requested subset.

\item[\Rcode{errthresh1}]
Maximum allowable probability of getting all zeros in a given bootstrapped column for the first dataset \Rcode{x}.  If a feature has a number of zeros that makes the probability of obtaining all zeros when sampling with replacement greater than this value, that feature will be excluded from the subsequent analysis.  This is to ensure that the standard deviation of the bootstrap sample is non-zero. (default: 0.0001).

\item[\Rcode{errthresh2}]
As \Rcode{errthresh1} but for the second dataset \Rcode{y}.

\item[\Rcode{verbose}]
If \Rcode{TRUE}, print periodic progress of the algorithm through the dataset(s), as well as including more detailed debugging output.  (default: \Rcode{FALSE}).

\item[\Rcode{iterations.gap}]
If \Rcode{verbose=TRUE}, the number of iterations between issuing status messages (default: 100).

\item[\Rcode{distributions}]
Optional output file for detailed log (if given) of all intermediate permutation and renormalization distributions.

\end{description}

\subsection{Output}

\Rcode{ccrepe} returns a \Rclass{list} containing both the calculation results and the parameters used:

\begin{description}
\setlength{\itemsep}{1em}

\item[\Rcode{sim.score}]
\Rclass{matrix} of simliarity scores for all requested comparisons.  The (\Rcode{i},\Rcode{j})th element corresponds to the similarity score of column \Rcode{i} (or the \Rcode{i}th column of \Rcode{subset.cols.1}) and column \Rcode{j} (or the \Rcode{j}th column of \Rcode{subset.cols.1}) in one dataset, or to the similarity score of column \Rcode{i} (or the \Rcode{i}th column of \Rcode{subset.cols.1}) in dataset \Rcode{x} and column \Rcode{j} (or the \Rcode{j}th column of \Rcode{subset.cols.2}) in dataset \Rcode{y} in the case of two datasets.

\item[\Rcode{p.values}]
\Rclass{matrix} of the corrected p-values for all requested comparisons.  The (\Rcode{i},\Rcode{j})th element corresponds to the p-value of the (\Rcode{i},\Rcode{j})th element of \Rcode{sim.score}.

\item[\Rcode{q.values}]
\Rclass{matrix} of the Benjamini-Hochberg-Yekutieli corrected p-values.  The (\Rcode{i},\Rcode{j})th element corresponds to the p-value of the (\Rcode{i},\Rcode{j})th element of \Rcode{sim.score}.

\end{description}

\subsection{Usage}	

<<eval=FALSE>>=
ccrepe(
 x = NA,
 y = NA,
 sim.score = cor,
 sim.score.args = list(),
 min.subj = 20,
 iterations = 1000,
 subset.cols.x = NULL,
 subset.cols.y = NULL,
 errthresh1 = 1e-04,
 errthresh2 = 1e-04,
 verbose = FALSE,
 iterations.gap = 100,
 distributions = NA)
@

\subsection{Example}

<<>>=
test.input <- matrix(c(
 0.29787234, 0.2978723, 0.2553191, 0.1489362,
 0.17073171, 0.3170732, 0.2682927, 0.2439024,
 0.09302326, 0.3255814, 0.2558140, 0.3255814,
 0.32352941, 0.3235294, 0.1470588, 0.2058824,
 0.17241379, 0.1724138, 0.4137931, 0.2413793,
 0.29729730, 0.2162162, 0.2702703, 0.2162162,
 0.22500000, 0.3250000, 0.2000000, 0.2500000,
 0.12820513, 0.3589744, 0.2307692, 0.2820513,
 0.20000000, 0.2250000, 0.2250000, 0.3500000,
 0.10256410, 0.3076923, 0.1794872, 0.4102564
 ), nrow=10, ncol=4, byrow=TRUE)

dimnames(test.input) <- list(c(
 "Sample 1", "Sample 2","Sample 3","Sample 4","Sample 5",
 "Sample 6","Sample 7","Sample 8","Sample 9","Sample 10"),
 c("Feature 1", "Feature 2", "Feature 3","Feature 4"))

test.output <- ccrepe(x=test.input, iterations=20, min.subj=10)
@
<<>>=
test.output
@

%---------------------------------------------------------
\section{nc.score} 
%---------------------------------------------------------

The \Rfunction{nc.score} similarity measure is an N-dimensional extension of the checkerboard score particularly suited to similarity score calculations between compositions derived from ecological relative abundance measurements.  In such cases, features typically represent species abundances, and the NC-score discretizes these continuous values into one of N bins before computing a normalized similarity of co-occurrence or co-exclusion.  This can be used as a standalone function or with \Rfunction{ccrepe} as above to obtain compositionality-corrected p-values.

\subsection{General Funcionality}

The NC-score is an extension to Diamond's checkerboard score (see References) to ordinal data.  The function as implemented here first performs basic quality control filtering of input relative abundance data.  It then transforms relative abundances to ordinal values based on user-provided or default bin thresholds.  It then computes a raw NC-score (analogous to a Pearson $\rho$):

% ***INSERT NC-SCORE INFO HERE***

\noindent
and finally normalizes this between -1 and 1 for $n$ bins based on theoretical maximum and minimum achievable values of:

% ***INSERT NC-SCORE INFO HERE***

\subsection{Arguments}

\begin{description}
\setlength{\itemsep}{1em}

\item[\Rcode{x}]
First numerical \Rclass{vector}, or single \Rclass{dataframe} or \Rclass{matrix}, containing relative abundances.  If the latter, columns are features, rows are samples.  Rows should therefore sum to a constant.

\item[\Rcode{y}]
If provided, second numerical \Rclass{vector} containing relative abundances.  If given, \Rcode{x} must be a \Rclass{vector} as well.

\item[\Rcode{bins}]
Either the number of bins to use or a \Rclass{vector} specifying bin edges.  If a single number is given, this is used as the number of bins with the \Rfunction{discretize} function of the package \CRANpkg{infotheo}.  If a \Rclass{vector} is specified, the function \Rfunction{findInterval} is used to discretize the data.  The default behavior is to use the defaults for the \Rfunction{discretize} function.

\item[\Rcode{verbose}]
Request verbose output.

\item[\Rcode{min.abundance}]
Minimum abundance threshold for quality control filtering.  For a feature to be included, it must take a value of at least \Rcode{min.abundance} in at least \Rcode{min.samples} percent of samples.

\item[\Rcode{min.samples}]
Minimum sample threshold for quality control filtering.  For a feature to be included, it must take a value of at least \Rcode{min.abundance} in at least \Rcode{min.samples} percent of samples.

\end{description}

\subsection{Output}

\Rfunction{nc.score} returns either a single number (if called with two vectors) or a \Rclass{matrix} of all pairwise scores (if called with a \Rclass{matrix}) of normalized scores.

\subsection{Usage}

<<eval=FALSE>>=
nc.score(
 x = NA,
 y = NA, 
 bins = NA, 
 verbose = FALSE,			 
 min.abundance = 1e-04,
 min.samples = 0.1)
@

\subsection{Example}

<<>>=
test.input <- matrix(c(
 0.29787234, 0.2978723, 0.2553191, 0.1489362, 
 0.17073171, 0.3170732, 0.2682927, 0.2439024, 
 0.09302326, 0.3255814, 0.2558140, 0.3255814, 
 0.32352941, 0.3235294, 0.1470588, 0.2058824, 
 0.17241379, 0.1724138, 0.4137931, 0.2413793, 
 0.29729730, 0.2162162, 0.2702703, 0.2162162, 
 0.22500000, 0.3250000, 0.2000000, 0.2500000, 
 0.12820513, 0.3589744, 0.2307692, 0.2820513, 
 0.20000000, 0.2250000, 0.2250000, 0.3500000, 
 0.10256410, 0.3076923, 0.1794872, 0.4102564 
 ), nrow=10, ncol=4, byrow = TRUE) 
test.output <- nc.score(x=test.input)
@
<<>>=
test.output
@

\end{document}
